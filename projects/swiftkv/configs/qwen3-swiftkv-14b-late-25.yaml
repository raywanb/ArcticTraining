type: swiftkv
code: ../train.py
micro_batch_size: 1
epochs: 1
gradient_accumulation_steps: 1
logits_loss_temp: 2.0
hidden_loss_layer: -2
model:
  name_or_path: Qwen/Qwen3-14B
  num_key_value_layers: 30
  kv_sharing_map:
    30: 29
    31: 29
    32: 29
    33: 29
    34: 29
    35: 29
    36: 29
    37: 29
    38: 29
    39: 29
  mlp_tuning_enabled: true
  layernorm_tuning_enabled: true
  attn_implementation: flash_attention_2
deepspeed:
  zero_optimization:
    stage: 2
data:
  sources:
  - type: huggingface_instruct
    name_or_path: Open-Orca/OpenOrca
    sample_count: 200000
  - type: huggingface_instruct
    name_or_path: nvidia/AceMath-Instruct-Training-Data
    split: general_sft_stage2
    sample_count: 200000
    kwargs:
      verification_mode: no_checks
  - type: huggingface_instruct
    name_or_path: openai/gsm8k
    sample_count: 200000
    split: train
    kwargs:
      name: main
  cache_dir: ./data-fast/data-cache
  num_proc: 16
  max_length: 8192
  apply_chat_template: false
logger:
  level: INFO
  output_dir: ./
  file_output_ranks:
  - 0
scheduler:
  warmup_ratio: 0.05
optimizer:
  betas:
  - 0.9
  - 0.999
  weight_decay: 0.0
  lr: 0.0002
checkpoint:
- type: huggingface
  save_every_n_epochs: 1
  output_dir: ./experiments/qwen3-swiftkv-14b-late-25
  save_end_of_training: true
wandb:
  enable: true
  entity: raywan-university-of-california-berkeley
  project: arctic-training
  name: qwen3-swiftkv-14b-late-25
